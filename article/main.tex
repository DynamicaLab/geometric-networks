\documentclass{article}   
\usepackage[left=1.5cm,right=1.5cm,top=2.3cm,bottom=2.3cm]{geometry}		
\usepackage[utf8]{inputenc} 										
%\usepackage[french]{babel}
\usepackage{fancyhdr}								
\usepackage{hyperref}								
\usepackage{booktabs,multirow,hhline}		
\usepackage{graphicx}				
\usepackage{bibentry}
\usepackage{wrapfig,caption}
\usepackage{subcaption}
\usepackage[compact]{titlesec}
\titlespacing{\section}{0pt}{2ex}{1ex}
\titlespacing{\subsection}{0pt}{1ex}{0ex}
\titlespacing{\subsubsection}{0pt}{0.5ex}{0ex}
\usepackage{color}												
\usepackage[dvipsnames]{xcolor}								
\usepackage{amsmath,amssymb,amsthm,nicefrac}
\usepackage{mathrsfs}										
\usepackage{wasysym,marvosym}
\usepackage{mathtools}
\usepackage{verbatim}										
\usepackage{minted}										
\usepackage{lipsum}
\usepackage{tikz}
\usepackage[american]{circuitikz}
\usepackage{siunitx}
\usepackage{physics}
\usepackage{float}
\usepackage{movie15}
\usepackage{multicol}

\usepackage[backend=biber, style=numeric]{biblatex}
\addbibresource{references.bib} %Imports bibliography file


\parindent=0pt									
\parskip=6pt									

\fancyheadoffset{0 cm}	

%---------------
\begin{document}

\begin{center}

    {\Large \textbf{Functional gradients in geometrically embedded networks}}\\
    
    \vspace{10 pt}
    Antoine Légaré,$^{1}$ \\
    \vspace{5 pt}
    
    $^1$\textit{Département de biochimie, de microbiologie et de bio-informatique, Université Laval, Québec (Québec), Canada}\\
    

\end{center}

\vspace{4 pt}

Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum. Lorem ipsum lorem ipsum.

\vspace{10 pt}

\begin{multicols}{2}

\section*{Introduction}

Neural field theory (NFT).

\section*{Results}

\section*{Functional gradients coincide with geometric modes in }

A principal assumption made by NFT is the exponential decay of connection weights with distance, a known feature of cortical connectivity which could form the structural basis for waves propagating through neural tissue. Similarly, the recent observation of geometric modes could be a direct consequence of strong local connectivity, where the cortical sheet would act as a dense, effectively continuous medium for wave propagation through the action of a Laplace-Beltrami operator. In both cases, short-range connections are the main drivers. Although long-range connections are present in the brain, their rarity and proportionally smaller effect on brain dynamics could in principle be greatly overshadowed by local connectivity. In Pang \textit{et al.}, a key result is the strong correspondence of functional gradients - spatially continuous measures of functional connectivity - with geometric modes derived from the shape of subcortical structures. Here, we demonstrate numerically that geometric functional gradients do emerge in arbitrary 3D shapes wherein locally connected neural networks are embedded with simple firing rate dynamics. We then investigate in the following section how this function-geometry correspondence breaks down when local connectivity is perturbed.

We begin by embedding $N=2000$ network nodes (e.g. neurons) uniformly in a $3D$ ellipsoid of major axis length $1$ and minor axis length $0.5$. Then, we connect neurons whose distance $d_{ij}$ is smaller than a certain radius $h$, which we set as $h=0.1$ for the present analysis. Edge weights are then drawn randomly from a certain distribution (which I need to describe here), with positive and negative weights representing excitatory and inhibitory synapses, respectively. Firing rate dynamics are then simulated with the following equation

$$\tau\frac{d\textbf{x}}{dt}=-\textbf{x} + g\textbf{W}\textbf{r},$$

where

$$\textbf{r}=\tanh{(\textbf{x})}.$$

$\textbf{x}(t)$ describes an internal variable for each neuron, analogous to a membrane potential, while $\textbf{r}(t)$ is the firing rate obtained through a nonlinearity $\tanh (\textbf{x})$. The parameter $\tau$ dictates the time constant of neurons, and $g$ is the coupling strength, which brings the network into a chaotic regime for $\tau>1$ (in the very large and dense limit) (cite).





\section*{Discussion}


\section*{Methods}


\newpage

%\bibliographystyle{plain}
%\bibliography{reference.bib}

\section*{Acknowledgements}

We acknowledge Calcul Québec and Digital Research Alliance of Canada for their technical support and computing infrastructures.

\section*{Author contributions}

\section*{Competing interests}

The authors declare no competing interests.

\end{multicols}

\newpage

\section*{References}

Format de section temporaire: Voici quelques références importantes pour le projet.

\begin{enumerate}
    \item \fullcite{GarcaTrillos2019}
    \subitem Démonstration de la convergence entre l'opérateur Laplacien sur un graphe dans une variété de dimension $m$ et l'opérateur de Laplace-Beltrami dans la limite $N\to\infty$ et $h\to0$. Le voisinage de chacun des $N$ noeuds est contenu dans une sphère de rayon $h$.
\end{enumerate}



\newpage

\section*{Supplementary Material}


\end{document}